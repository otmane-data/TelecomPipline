ğŸ“¡ Pipeline TÃ©lÃ©com â€“ GÃ©nÃ©ration, MÃ©diation, Tarification, Stockage & Visualisation

ğŸ§¾ PrÃ©sentation

Ce projet implÃ©mente un pipeline complet de traitement de donnÃ©es dans un contexte tÃ©lÃ©com, en allant de la gÃ©nÃ©ration de donnÃ©es simulÃ©es jusquâ€™Ã  leur visualisation interactive.

ğŸ”„ Ã‰tapes principales :

ğŸ› ï¸ GÃ©nÃ©ration : CrÃ©ation de donnÃ©es tÃ©lÃ©com simulÃ©es en Python.

ğŸ“¡ MÃ©diation : Envoi des Ã©vÃ©nements via Apache Kafka.

âš™ï¸ Tarification : Traitement des Ã©vÃ©nements et gÃ©nÃ©ration de factures avec Apache Spark.

ğŸ—„ï¸ Stockage : Insertion des factures dans PostgreSQL.

ğŸ“Š Visualisation : Affichage dynamique via une application Streamlit.

ğŸ§± Architecture

 ![Architecture du projet](sets/Diagramme%20sans%20nom.drawio%20(2).png)

text
Copier
Modifier
[Data Generator] â†’ [Kafka] â†’ [Spark Streaming] â†’ [PostgreSQL] â†’ [Streamlit App]
ğŸ”§ PrÃ©requis
Assurez-vous dâ€™avoir les outils suivants installÃ©s :

Python â‰¥ 3.8

Docker & Docker Compose

Apache Kafka

Apache Spark

PostgreSQL

Streamlit

ğŸš€ Installation
1. Cloner le dÃ©pÃ´t
bash
Copier
Modifier
git clone <repo_url>
cd big-data
2. Lancer les services avec Docker Compose
bash
Copier
Modifier
docker-compose up --build
Cela dÃ©marre les services nÃ©cessaires (Kafka, PostgreSQL, Spark, etc.).

3. Installer les dÃ©pendances Python
bash
Copier
Modifier
pip install -r requirements.txt
âš™ï¸ Lancement des modules
â–¶ï¸ GÃ©nÃ©rateur de donnÃ©es
Script de simulation dâ€™Ã©vÃ©nements envoyÃ©s Ã  Kafka :

bash
Copier
Modifier
python src/data_generator/generator.py
â–¶ï¸ Consommateur Kafka â†’ PostgreSQL

Consomme les messages Kafka et les insÃ¨re dans la base PostgreSQL :

bash
Copier
Modifier
python consomateur.py
â–¶ï¸ Traitement Spark (Tarification)

ExÃ©cuter le traitement et la gÃ©nÃ©ration de factures dans :

bash
Copier
Modifier
data/otmane.ipynb
Ce notebook Spark lit depuis Kafka, applique la logique mÃ©tier et produit les factures.

â–¶ï¸ Visualisation avec Streamlit
Lancer lâ€™application :

bash
Copier
Modifier
streamlit run streamlit_app.py
Accessible via http://localhost:8501

big-data/

â”œâ”€â”€ src/

â”‚   â””â”€â”€ data_generator/         # GÃ©nÃ©rateur de donnÃ©es simulÃ©es

â”œâ”€â”€ consomateur.py              # Kafka â†’ PostgreSQL

â”œâ”€â”€ data/

â”‚   â””â”€â”€ otmane.ipynb            # Traitement Spark

â”œâ”€â”€ streamlit_app.py            # Interface Streamlit

â”œâ”€â”€ requirements.txt            # DÃ©pendances Python

â”œâ”€â”€ docker-compose.yml          # Services Docker

â””â”€â”€ README.md                   # Ce fichier

ğŸ§ª Exemple dâ€™utilisation

Les factures tÃ©lÃ©com sont enregistrÃ©es dans la table invoices de la base PostgreSQL.

Lâ€™interface Streamlit permet :

ğŸ” de filtrer les clients,

ğŸ“ˆ de visualiser les montants par cycle,

ğŸ“„ dâ€™explorer les dÃ©tails de chaque facture.

ğŸ‘¥ Auteurs
Projet rÃ©alisÃ© par Otmane et collaborateurs, dans le cadre dâ€™un projet Big Data.
